name: Load Testing

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - development
        - staging
        - production
      duration:
        description: 'Test duration in minutes'
        required: false
        default: '5'
        type: string
      users:
        description: 'Number of concurrent users'
        required: false
        default: '100'
        type: string
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  pull_request:
    paths:
      - 'backend/**'
      - 'frontend/**'
      - 'load-testing/**'

concurrency:
  group: load-testing-${{ github.ref }}
  cancel-in-progress: true

jobs:
  load-test:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'development' }}
    env:
      SMS_ENV: ${{ github.event.inputs.environment || 'development' }}
      AUTH_MODE: disabled
      AUTH_ENABLED: 'false'
      CI_SKIP_AUTH: 'true'
      RATE_LIMIT_AUTH_PER_MINUTE: '1000000'
      RATE_LIMIT_READ_PER_MINUTE: '1000000'
      RATE_LIMIT_WRITE_PER_MINUTE: '1000000'
      RATE_LIMIT_HEAVY_PER_MINUTE: '1000000'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: |
          load-testing/requirements.txt
          archive/cleanup-feb2026/legacy-load-testing/root/requirements.txt
          backend/requirements.txt

    - name: Resolve load testing paths
      id: loadtest
      run: |
        if [ -d "load-testing" ]; then
          echo "requirements=load-testing/requirements.txt" >> $GITHUB_OUTPUT
          echo "scripts=load-testing/scripts" >> $GITHUB_OUTPUT
          echo "results=load-testing/results" >> $GITHUB_OUTPUT
          echo "reports=load-testing/reports" >> $GITHUB_OUTPUT
          echo "baseline=load-testing/baseline.json" >> $GITHUB_OUTPUT
          echo "pythonpath=load-testing" >> $GITHUB_OUTPUT
          echo "rootdir=load-testing" >> $GITHUB_OUTPUT
        elif [ -d "archive/cleanup-feb2026/legacy-load-testing" ]; then
          echo "requirements=archive/cleanup-feb2026/legacy-load-testing/root/requirements.txt" >> $GITHUB_OUTPUT
          echo "scripts=archive/cleanup-feb2026/legacy-load-testing/scripts" >> $GITHUB_OUTPUT
          echo "results=archive/cleanup-feb2026/legacy-load-testing/results" >> $GITHUB_OUTPUT
          echo "reports=archive/cleanup-feb2026/legacy-load-testing/results" >> $GITHUB_OUTPUT
          echo "baseline=archive/cleanup-feb2026/legacy-load-testing/root/baseline.json" >> $GITHUB_OUTPUT
          echo "pythonpath=archive/cleanup-feb2026/legacy-load-testing/root:archive/cleanup-feb2026/legacy-load-testing/root/locust" >> $GITHUB_OUTPUT
          echo "rootdir=archive/cleanup-feb2026/legacy-load-testing/root" >> $GITHUB_OUTPUT
        else
          echo "missing=true" >> $GITHUB_OUTPUT
        fi

    - name: Guard missing load testing suite
      if: steps.loadtest.outputs.missing == 'true'
      run: |
        echo "Load testing suite not found. Skipping run."

    - name: Install dependencies
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        pip install -r ${{ steps.loadtest.outputs.requirements }}
        pip install -r backend/requirements.txt

    - name: Initialize database
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        # Run migrations to initialize database before backend starts
        export PYTHONPATH="${{ github.workspace }}"
        python -c "from backend.scripts.migrate.runner import run_migrations; run_migrations(verbose=True)"
        echo "Database initialized successfully"

    - name: Start backend server (background)
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        # Start uvicorn in background so load tests can target localhost:8080
        nohup python -m uvicorn backend.main:app --host 0.0.0.0 --port 8080 &>/dev/null &
        # Wait for backend to be ready
        for i in {1..30};
        do
          if curl -s http://127.0.0.1:8080/health > /dev/null; then
            echo "Backend is ready"
            break
          fi
          echo "Waiting for backend... ($i/30)"
          sleep 1
        done
        # Final check
        curl -f http://127.0.0.1:8080/health

    - name: Run smoke test
      if: steps.loadtest.outputs.missing != 'true'
      env:
        PYTHONPATH: ${{ steps.loadtest.outputs.pythonpath }}
      run: |
        cd ${{ steps.loadtest.outputs.rootdir || '.' }}
        echo "Running smoke test from directory: $(pwd)"
        echo "PYTHONPATH: $PYTHONPATH"
        python ${{ github.workspace }}/${{ steps.loadtest.outputs.scripts }}/run_load_tests.py \
          --scenario smoke \
          --env "${{ env.SMS_ENV }}" \
          --ci \
          --verbose || {
          echo "❌ Smoke test failed with exit code $?"
          exit 1
        }

    - name: Run load test
      continue-on-error: true
      if: steps.loadtest.outputs.missing != 'true'
      env:
        PYTHONPATH: ${{ steps.loadtest.outputs.pythonpath }}
      run: |
        cd ${{ steps.loadtest.outputs.rootdir || '.' }}
        echo "Running load test from directory: $(pwd)"
        python ${{ github.workspace }}/${{ steps.loadtest.outputs.scripts }}/run_load_tests.py \
          --scenario ${{ github.event.inputs.environment == 'production' && 'medium' || 'light' }} \
          --env "${{ env.SMS_ENV }}" \
          --ci \
          --verbose || {
          echo "⚠️  Load test failed with exit code $? (continuing due to continue-on-error)"
        }

    - name: Analyze results
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        cd ${{ steps.loadtest.outputs.rootdir || '.' }}
        python ${{ github.workspace }}/${{ steps.loadtest.outputs.scripts }}/analyze_results.py --results-dir ${{ github.workspace }}/${{ steps.loadtest.outputs.results }}

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always() && steps.loadtest.outputs.missing != 'true'
      with:
        name: load-test-results-${{ github.event.inputs.environment || 'development' }}-${{ github.run_number }}
        path: |
          ${{ steps.loadtest.outputs.results }}/
          ${{ steps.loadtest.outputs.reports }}/
        retention-days: 30

    - name: Performance regression check
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        cd ${{ steps.loadtest.outputs.rootdir || '.' }}
        CURRENT_FILE=$(ls -t ${{ github.workspace }}/${{ steps.loadtest.outputs.results }}/analysis_*.json 2>/dev/null | head -n 1)
        if [ -z "$CURRENT_FILE" ]; then
          echo "❌ No analysis_*.json files found for regression check"
          exit 1
        fi
        python ${{ github.workspace }}/${{ steps.loadtest.outputs.scripts }}/check_regression.py --baseline ${{ github.workspace }}/${{ steps.loadtest.outputs.baseline }} --current "$CURRENT_FILE"

    - name: Notify on failure
      if: failure()
      run: |
        echo "Load testing failed - check artifacts for details"
        # Add notification logic here (Slack, Teams, etc.)

  performance-report:
    runs-on: ubuntu-latest
    needs: load-test
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Resolve load testing paths
      id: loadtest
      run: |
        if [ -d "load-testing" ]; then
          echo "scripts=load-testing/scripts" >> $GITHUB_OUTPUT
          echo "requirements=load-testing/requirements.txt" >> $GITHUB_OUTPUT
          echo "results=load-testing/results" >> $GITHUB_OUTPUT
          echo "rootdir=load-testing" >> $GITHUB_OUTPUT
        elif [ -d "archive/cleanup-feb2026/legacy-load-testing" ]; then
          echo "scripts=archive/cleanup-feb2026/legacy-load-testing/scripts" >> $GITHUB_OUTPUT
          echo "requirements=archive/cleanup-feb2026/legacy-load-testing/root/requirements.txt" >> $GITHUB_OUTPUT
          echo "results=archive/cleanup-feb2026/legacy-load-testing/results" >> $GITHUB_OUTPUT
          echo "rootdir=archive/cleanup-feb2026/legacy-load-testing/root" >> $GITHUB_OUTPUT
        else
          echo "missing=true" >> $GITHUB_OUTPUT
        fi

    - name: Install dependencies
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        pip install -r ${{ steps.loadtest.outputs.requirements }}

    - name: Download test results
      if: steps.loadtest.outputs.missing != 'true'
      uses: actions/download-artifact@v4
      with:
        name: load-test-results-${{ github.event.inputs.environment || 'development' }}-${{ github.run_number }}
        path: load-test-results

    - name: Generate performance report
      if: steps.loadtest.outputs.missing != 'true'
      run: |
        cd ${{ steps.loadtest.outputs.rootdir || '.' }}
        RESULTS_DIR="${{ github.workspace }}/load-test-results/${{ steps.loadtest.outputs.results }}"
        if [ ! -d "$RESULTS_DIR" ]; then
          RESULTS_DIR=$(find "${{ github.workspace }}/load-test-results" -type f -name "analysis_*.json" -printf "%h\n" | head -n 1)
        fi
        if [ -z "$RESULTS_DIR" ] || [ ! -d "$RESULTS_DIR" ]; then
          echo "❌ Results directory not found under load-test-results"
          exit 1
        fi
        python ${{ github.workspace }}/${{ steps.loadtest.outputs.scripts }}/generate_report.py --input "$RESULTS_DIR" --output ${{ github.workspace }}/performance-report.html

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      if: steps.loadtest.outputs.missing != 'true'
      with:
        name: performance-report-${{ github.event.inputs.environment || 'development' }}-${{ github.run_number }}
        path: performance-report.html
        retention-days: 90
