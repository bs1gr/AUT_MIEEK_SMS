# Fix 2: E2E Tests Environment
# File: .github/workflows/e2e-tests.yml

name: E2E Tests

on:
  pull_request:
    branches: [main, develop]
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'installer/**'
      - 'tools/**'
  push:
    branches: [main, develop]
    paths-ignore:
      - '**/*.md'
      - 'docs/**'
      - 'installer/**'
      - 'tools/**'
  workflow_dispatch:

concurrency:
  group: e2e-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    # E2E tests must pass - they verify end-to-end functionality
    # If tests fail, the issue must be fixed before merge
    continue-on-error: false

    steps:
      - uses: actions/checkout@v4

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: backend/requirements*.txt

      # FIX 1: Add system dependencies check
      - name: Update system packages
        run: |
          sudo apt-get update || echo "Failed to update apt, continuing..."

      - name: Determine Playwright version
        id: pwver
        working-directory: ./frontend
        run: |
          VERSION=$(node -p "require('./package.json').devDependencies['@playwright/test'].replace(/^\^/, '')")
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          MINOR=$(node -p "require('./package.json').devDependencies['@playwright/test'].replace(/^\^/, '').split('.').slice(0,2).join('.')")
          echo "minor=$MINOR" >> $GITHUB_OUTPUT
          echo "Playwright version: $VERSION"

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ steps.pwver.outputs.version }}
          restore-keys: |
            playwright-${{ runner.os }}-${{ steps.pwver.outputs.minor }}
            playwright-${{ runner.os }}-

      - name: Install backend dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci

      # FIX 2: Install Playwright with system dependencies explicitly
      - name: Install Playwright browsers with dependencies
        working-directory: ./frontend
        run: |
          echo "Installing Playwright browsers..."
          npx playwright install chromium --with-deps
          echo "Verifying Playwright installation..."
          npx playwright --version

      - name: Build frontend
        working-directory: ./frontend
        run: npm run build

      # FIX 3: Add database initialization
      - name: Prepare data directory
        run: mkdir -p ./data

      # FIX 4: Initialize database with migrations before seeding
      - name: Initialize database
        working-directory: ./backend
        run: |
          echo "Running Alembic migrations..."
          python -c "from backend.run_migrations import run_migrations; run_migrations()" || echo "Migration warning (may already be up-to-date)"

      - name: Seed test data
        run: |
          echo "Seeding E2E test data..."
          python backend/seed_e2e_data.py

      - name: Force reseed with test user
        run: |
          echo "Force reseeding to ensure test user exists..."
          python -c "import sys; sys.path.insert(0, '.'); from backend.seed_e2e_data import seed_e2e_data; seed_e2e_data(force=True)"

      - name: Validate seed data
        run: |
          echo "Validating E2E test data..."
          python backend/validate_e2e_data.py

      # FIX 5: Add health check before starting tests
      - name: Start backend in background
        env:
          CSRF_ENABLED: '0'
          AUTH_MODE: permissive
          AUTH_LOGIN_THROTTLE_ENABLED: '0'
          AUTH_USER_LOCKOUT_ENABLED: '0'
          SERVE_FRONTEND: '1'
          DATABASE_URL: sqlite:///./data/student_management.db
        run: |
          echo "Starting backend server..."
          echo "Frontend build exists: $(test -f frontend/dist/index.html && echo 'YES' || echo 'NO')"
          python -m uvicorn backend.main:app --host 127.0.0.1 --port 8000 &
          echo $! > backend.pid
          sleep 5

          # Wait for backend to be ready with better error handling
          echo "Waiting for backend health check..."
          MAX_ATTEMPTS=60
          ATTEMPT=0
          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT + 1))
            echo "Health check attempt $ATTEMPT/$MAX_ATTEMPTS..."
            HEALTH=$(curl -s http://127.0.0.1:8000/health 2>&1 || echo "FAILED")
            if echo "$HEALTH" | grep -q '"status"'; then
              echo "âœ… Backend is ready (attempt $ATTEMPT/$MAX_ATTEMPTS)"
              echo "Health response: $HEALTH" | head -1
              break
            fi
            if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
              echo "âŒ Backend failed to start within $(($MAX_ATTEMPTS / 2)) seconds"
              echo "Last health check response:"
              curl -v http://127.0.0.1:8000/health 2>&1 || true
              echo "\nTrying root endpoint:"
              curl -v http://127.0.0.1:8000/ 2>&1 | head -20 || true
              if [ -f backend.pid ]; then
                echo "Backend process status:"
                ps aux | grep $(cat backend.pid) || echo "Process not found"
              fi
              exit 1
            fi
            echo "â³ Waiting for backend... ($ATTEMPT/$MAX_ATTEMPTS)"
            sleep 1
          done

      # FIX: Validate login endpoint works before running E2E tests
      - name: Check login health
        run: |
          echo "=== Verifying Authentication Setup ==="
          echo ""
          echo "1. Checking if test user exists in database..."
          python -c "
          import sys
          sys.path.insert(0, '.')
          from sqlalchemy import create_engine
          from sqlalchemy.orm import sessionmaker
          from backend.models import User

          engine = create_engine('sqlite:///./data/student_management.db')
          Session = sessionmaker(bind=engine)
          db = Session()

          user = db.query(User).filter(User.email == 'test@example.com').first()
          if user:
              print(f'âœ… Test user found: {user.email} (role: {user.role}, active: {user.is_active})')
              print(f'   Has password hash: {bool(user.hashed_password)}')
              db.close()
              sys.exit(0)
          else:
              print('âŒ Test user NOT found in database!')
              db.close()
              sys.exit(1)
          "

          echo ""
          echo "2. Testing login endpoint with test credentials..."
          python backend/check_login_health.py

          echo ""
          echo "=== Authentication validation complete ==="

      - name: Run E2E tests
        working-directory: ./frontend
        env:
          PLAYWRIGHT_BASE_URL: http://127.0.0.1:8000
          DEBUG: 'pw:api'
          VITE_API_URL: http://127.0.0.1:8000/api/v1
        timeout-minutes: 40
        id: e2e
        run: |
          echo "=== Sanity check: Verify backend serving frontend ==="
          echo "Checking root endpoint /..."
          curl -s -I http://127.0.0.1:8000/ | head -5

          echo ""
          echo "=== Checking for login form in HTML response ==="
          curl -s http://127.0.0.1:8000/ | grep -o 'auth-login-email\|auth-login-password' || echo "âš ï¸  Login form IDs not found in HTML"

          echo ""
          echo "=== Checking /api response ==="
          curl -s http://127.0.0.1:8000/api | head -100

          echo ""
          echo "=== Allowing app to settle (5s) ==="
          sleep 5

          echo ""
          echo "=== Running Playwright E2E tests ==="
          set +e
          npm run e2e -- --reporter=list --workers=1 --timeout=120000 --max-failures=3
          STATUS=$?
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          exit $STATUS

      - name: Kill backend
        if: always()
        run: |
          if [ -f backend.pid ]; then
            echo "Stopping backend (PID: $(cat backend.pid))..."
            kill $(cat backend.pid) 2>/dev/null || echo "Backend already stopped"
            rm backend.pid
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results
          path: |
            frontend/playwright-report/
            frontend/test-results/
          retention-days: 30
          if-no-files-found: ignore

      - name: Extract test results
        if: always()
        id: test-results
        run: |
          echo "Extracting test results..."
          if [ -f frontend/playwright-report/index.html ]; then
            # Try to extract test counts from report
            PASSED=$(grep -o 'passed">[0-9]*' frontend/playwright-report/index.html 2>/dev/null | grep -o '[0-9]*' | head -1 || echo "0")
            FAILED=$(grep -o 'failed">[0-9]*' frontend/playwright-report/index.html 2>/dev/null | grep -o '[0-9]*' | head -1 || echo "0")
            SKIPPED=$(grep -o 'skipped">[0-9]*' frontend/playwright-report/index.html 2>/dev/null | grep -o '[0-9]*' | head -1 || echo "0")
            TOTAL=$((PASSED + FAILED + SKIPPED))

            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILED" >> $GITHUB_OUTPUT
            echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
            echo "total=$TOTAL" >> $GITHUB_OUTPUT

            echo "Test Results: $PASSED passed, $FAILED failed, $SKIPPED skipped (Total: $TOTAL)"
          else
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "skipped=0" >> $GITHUB_OUTPUT
            echo "total=0" >> $GITHUB_OUTPUT
            echo "âš ï¸  No test report found"
          fi

      - name: Comment E2E result on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const status = core.getInput('status', { required: false }) || '${{ steps.e2e.outputs.status }}';
            const passed = '${{ steps.test-results.outputs.passed }}' || '0';
            const failed = '${{ steps.test-results.outputs.failed }}' || '0';
            const skipped = '${{ steps.test-results.outputs.skipped }}' || '0';
            const total = '${{ steps.test-results.outputs.total }}' || '0';

            const conclusion = status === '0' ? 'âœ… Passed' : 'âŒ Failed';
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;

            const body = [
              `### ðŸŽ­ E2E Test Results`,
              '',
              `**Status:** ${conclusion}`,
              '',
              `**Tests:**`,
              `- âœ… Passed: ${passed}`,
              `- âŒ Failed: ${failed}`,
              `- â­ï¸ Skipped: ${skipped}`,
              `- ðŸ“Š Total: ${total}`,
              '',
              `**Resources:**`,
              `- [View full logs](${runUrl})`,
              `- Artifacts: \`e2e-test-results\` (screenshots, videos, reports)`,
              '',
              failed > 0 ? 'âš ï¸  **Action required:** Please review failed tests and screenshots in artifacts.' : 'ðŸŽ‰ All E2E tests passed!',
            ].join('\n');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });

      - name: Upload backend logs (if failed)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-backend-logs
          path: backend/logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: Collect E2E test metrics (NEW)
        if: always()
        id: metrics
        run: |
          echo "=== Collecting E2E Test Metrics ==="
          mkdir -p ci-artifacts

          python scripts/e2e_metrics_collector.py \
            --report frontend/test-results/report.json \
            --run-id "${{ github.run_id }}" \
            --branch "${{ github.ref_name }}" \
            --commit "${{ github.sha }}" \
            --output ci-artifacts/metrics.json \
            || echo "âš ï¸  Metrics collection encountered an issue (non-blocking)"

          if [ -f ci-artifacts/metrics.json ]; then
            echo "âœ… Metrics collected successfully"
            cat ci-artifacts/metrics.json
          else
            echo "âš ï¸  No metrics file generated"
          fi

      - name: Detect E2E failure patterns (NEW)
        if: always()
        run: |
          echo "=== Analyzing Test Failure Patterns ==="
          mkdir -p ci-artifacts

          python scripts/e2e_failure_detector.py \
            --report frontend/test-results/report.json \
            --output ci-artifacts/failure-patterns.json \
            || echo "âš ï¸  Failure detection encountered an issue (non-blocking)"

          if [ -f ci-artifacts/failure-patterns.json ]; then
            echo "âœ… Failure patterns analyzed"
            python -m json.tool ci-artifacts/failure-patterns.json || true
          fi

      - name: Archive metrics and patterns (NEW)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-metrics-and-patterns
          path: ci-artifacts/
          retention-days: 90
          if-no-files-found: ignore

      - name: Generate test summary
        if: always()
        run: |
          echo "## ðŸŽ­ E2E Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          STATUS="${{ steps.e2e.outputs.status }}"
          if [ "$STATUS" = "0" ]; then
            echo "âœ… **Status:** All tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Status:** Tests failed (exit code: $STATUS)" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Passed: ${{ steps.test-results.outputs.passed }}" >> $GITHUB_STEP_SUMMARY
          echo "- âŒ Failed: ${{ steps.test-results.outputs.failed }}" >> $GITHUB_STEP_SUMMARY
          echo "- â­ï¸ Skipped: ${{ steps.test-results.outputs.skipped }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š Total: ${{ steps.test-results.outputs.total }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Monitoring Data" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š Metrics and failure patterns saved to \`e2e-metrics-and-patterns\` artifact (90-day retention)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- Test report, screenshots, and videos available in \`e2e-test-results\` artifact" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.test-results.outputs.failed }}" != "0" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸  **Failed tests detected** - check artifacts for screenshots and trace files" >> $GITHUB_STEP_SUMMARY
          fi
